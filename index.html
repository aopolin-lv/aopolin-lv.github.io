<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Qi Lv</title>
  <meta name="author" content="Qi Lv">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <!-- Header Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Qi Lv
                  </p>
                  <p>
                    I am a third-year Ph.D. student at Harbin Institute of Technology (Shenzhen) and Great Bay
                    University, advised by <a href="https://liqiangnie.github.io/index.html">Liqiang Nie</a> (IARP
                    Fellow), and <a href="https://scholar.google.com/citations?hl=zh-CN&user=Oo7c22wAAAAJ">Michael Yu Wang</a>
                    (IEEE/ASME/HKIE Fellow), and co-supervised by <a href="https://xiang-deng-dl.github.io/">Xiang Deng</a>.
                    Currently I am a visiting student at the National University of Singapore, working with <a href="https://scholar.google.com/citations?hl=zh-CN&user=h1-3lSoAAAAJ">Mike Shou</a>.
                    Before, I received M.S and B.E from Soochow University.
                    <br><br>
                    My research focuses on embodied AI and natural language processing, particularly on integrating
                    multimodal large language models with robotic systems. I am interested in enabling robots to better
                    perceive, reason, and act in the physical world through language-vision-action alignment.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:aopolin.ii@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/qilv_cv.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=4obt24UAAAAJ&hl">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/Aopolin">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://github.com/Aopolin-Lv/">Github</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/qi-lv-075614311/">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:27%;max-width:27%">
                  <a href="images/personal_pic.png">
                    <img style="width:100%;max-width:100%;aspect-ratio: 1/1;object-fit: cover; border-radius:50%;"
                         alt="profile photo" 
                         src="images/personal_pic.png" 
                         class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications Header -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>
                    Selected Publications 
                    <span style="font-size: 14px; font-weight: normal;">
                      (<eq>*</eq> denotes equal contribution)
                    </span>
                  </h2>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications List -->
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- F1-VLA Paper -->
              <tr onmouseout="f1_stop()" onmouseover="f1_start()">
                <td style="padding:16px;width:40%;vertical-align:top">
                  <div class="one">
                    <div class="two" id='f1_image'>
                      <video width=100% height=100% muted autoplay loop>
                        <source src="images/f1-vla.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='images/f1-vla.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function f1_start() {
                      document.getElementById('f1_image').style.opacity = "1";
                    }
                    function f1_stop() {
                      document.getElementById('f1_image').style.opacity = "0";
                    }
                    f1_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:top">
                  <a href="https://aopolin-lv.github.io/F1-VLA/">
                    <span class="papertitle">
                      F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions
                    </span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong><eq>*</eq>,
                  Weijie Kong<eq>*</eq>, 
                  Hao Li<eq>*</eq>, 
                  Jia Zeng, 
                  Zherui Qiu, 
                  Delin Qu, 
                  Haoming Song, 
                  Qizhi Chen,
                  Xiang Deng, 
                  Jiangmiao Pang
                  <br>
                  <em>arxiv</em>, 2025
                  <br>
                  <a href="https://aopolin-lv.github.io/F1-VLA/">project page</a> /
                  <a href="https://arxiv.org/abs/2509.06951">arXiv</a> /
                  <a href="https://github.com/InternRobotics/F1-VLA">code</a>
                  &nbsp;
                  <a href="https://huggingface.co/InternRobotics/F1-VLA">
                    <img src="https://img.shields.io/badge/F1--VLA-Model-FF7F00?logo=huggingface&logoColor=brightyellow"
                         alt="EO-1 Model" />
                  </a>
                  <p></p>
                  <p>
                    A novel paradigm integrating visual foresight generation into the decision-making pipeline, enabling
                    robots to plan and execute complex tasks in dynamic environments.
                  </p>
                </td>
              </tr>

              <!-- star Paper -->
              <tr onmouseout="star_stop()" onmouseover="star_start()">
                <td style="padding:16px;width:40%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='star_image'>
                      <video width=100% height=100% muted autoplay loop>
                        <source src="images/star.png" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='images/star.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function star_start() {
                      document.getElementById('star_image').style.opacity = "1";
                    }
                    function star_stop() {
                      document.getElementById('star_image').style.opacity = "0";
                    }
                    afllm_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:middle">
                  <a href="https://icml.cc/virtual/2025/poster/44123">
                    <span class="papertitle">
                      STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization
                    </span>
                  </a>
                  <br>
                  Hao Li,
                  <strong>Qi Lv</strong>,
                  Rui Shao,
                  Xiang Deng,
                  Yinchuan Li,
                  Jianye Hao,
                  Liqiang Nie,
                  <br>
                  <em>ICML</em>, 2025, Spotlight
                  <br>
                  <a href="https://arxiv.org/abs/2506.03863">arXiv</a> /
                  <a href="https://github.com/JiuTian-VL/STAR">code</a>
                  <p></p>
                  <p>
                    A framework for robust skill learning and composition that mitigates codebook collapse and models causal dependencies between skills, by introducing rotation-augmented skill quantization and a causal skill transformer.
                  </p>
                </td>
              </tr>

              <!-- KStar Diffuser Paper -->
              <tr onmouseout="stard_stop()" onmouseover="stard_start()">
                <td style="padding:16px;width:40%;vertical-align:top">
                  <div class="one">
                    <div class="two" id='nexf_image'>
                      <img src='images/stard.png' width=100%>
                    </div>
                    <img src='images/stard.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function stard_start() {
                      document.getElementById('nexf_image').style.opacity = "1";
                    }
                    function stard_stop() {
                      document.getElementById('nexf_image').style.opacity = "0";
                    }
                    stard_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:middle">
                  <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Lv_Spatial-Temporal_Graph_Diffusion_Policy_with_Kinematic_Modeling_for_Bimanual_Robotic_CVPR_2025_paper.html">
                    <span class="papertitle">
                      Spatial-Temporal Graph Diffusion Policy with Kinematic Modeling for Bimanual Robotic Manipulation
                    </span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong>, 
                  Hao Li, 
                  Xiang Deng, 
                  Rui Shao, 
                  Yinchuan Li, 
                  Jianye Hao, 
                  Longxiang Gao, 
                  Michael Yu Wang, 
                  Liqiang Nie
                  <br>
                  <em>CVPR</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2503.10743">arXiv</a>
                  <p></p>
                  <p>
                    KStar Diffuser leverages dynamic spatial-temporal robot graphs and differentiable kinematics to
                    produce physically feasible, structure-aware bimanual manipulation policies.
                  </p>
                </td>
              </tr>

              <!-- 3d-afllm Paper -->
              <tr onmouseout="afllm_stop()" onmouseover="afllm_start()">
                <td style="padding:16px;width:40%;vertical-align:top">
                  <div class="one">
                    <div class="two" id='afllm_image'>
                      <video width=100% height=100% muted autoplay loop>
                        <source src="images/afllm2.png" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='images/afllm2.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function afllm_start() {
                      document.getElementById('afllm_image').style.opacity = "1";
                    }
                    function afllm_stop() {
                      document.getElementById('afllm_image').style.opacity = "0";
                    }
                    afllm_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:top">
                  <a href="https://arxiv.org/abs/2502.20041">
                    <span class="papertitle">
                      3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary Affordance Detection in 3D Worlds
                    </span>
                  </a>
                  <br>
                  Hengshuo Chu,
                  Xiang Deng,
                  <strong>Qi Lv</strong>,
                  Xiaoyang Chen,
                  Yinchuan Li,
                  Jianye Hao,
                  Liqiang Nie,
                  <br>
                  <em>ICLR</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2502.20041">arXiv</a>
                  <p></p>
                  <p>
                    We formulates 3D affordance detection as a language-driven reasoning task for open-world scenes. 
                    By integrating LLM reasoning and multi-stage training, it achieves improved open-vocabulary affordance segmentation.
                  </p>
                </td>
              </tr>

              <!-- Decision Mamba Paper -->
              <tr onmouseout="dm_stop()" onmouseover="dm_start()">
                <td style="padding:16px;width:40%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='dm_image'>
                      <img src='images/dm.png' width=100%>
                    </div>
                    <img src='images/dm.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function dm_start() {
                      document.getElementById('dm_image').style.opacity = "1";
                    }
                    function dm_stop() {
                      document.getElementById('dm_image').style.opacity = "0";
                    }
                    dm_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:bottom">
                  <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/288b63aa98084366c4536ba0574a0f22-Abstract-Conference.html">
                    <span class="papertitle">
                      Decision Mamba: A Multi-Grained State Space Model with Self-Evolution Regularization for Offline RL
                    </span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong>, 
                  Xiang Deng, 
                  Gongwei Chen, 
                  Michael Yu Wang, 
                  Liqiang Nie
                  <br>
                  <em>NeurIPS</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2503.10743">arXiv</a> /
                  <a href="https://github.com/aopolin-lv/DecisionMamba">code</a>
                  <p></p>
                  <p>
                    We introduces a novel multi-grained Mamba architecture that jointly models historical hidden states
                    and intra-step RTG–state–action relations, enabling more robust offline RL under out-of-distribution
                    settings.
                  </p>
                </td>
              </tr>

              <!-- RoboMP2 Paper -->
              <tr onmouseout="robomp2_stop()" onmouseover="robomp2_start()">
                <td style="padding:16px;width:40%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='robomp2_image'>
                      <img src='images/robomp2.png' width=100%>
                    </div>
                    <img src='images/robomp2.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function robomp2_start() {
                      document.getElementById('robomp2_image').style.opacity = "1";
                    }
                    function robomp2_stop() {
                      document.getElementById('robomp2_image').style.opacity = "0";
                    }
                    robomp2_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:bottom">
                  <a href="https://proceedings.mlr.press/v235/lv24a.html">
                    <span class="papertitle">
                      RoboMP<sup>2</sup>: A Robotic Multimodal Perception-Planning Framework with Multimodal Large Language Models
                    </span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong>, 
                  Hao Li, 
                  Xiang Deng, 
                  Rui Shao, 
                  Michael Yu Wang, 
                  Liqiang Nie
                  <br>
                  <em>ICML</em>, 2024
                  <br>
                  <a href="https://aopolin-lv.github.io/RoboMP2.github.io/">project page</a> /
                  <a href="https://arxiv.org/abs/2404.04929">arXiv</a> /
                  <a href="https://github.com/aopolin-lv/RoboMP2">code</a>
                  <p></p>
                  <p>
                    A multimodal perception–planning framework that grounds MLLM reasoning in embodied robotic manipulation. 
                    It improves generalization by combining goal-conditioned perception with retrieval-augmented planning.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- Education Header -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Education & Experience</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Education List -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:5px 16px;width:100%;vertical-align:top;">
                  <div style="display:flex;gap:12px;">
                    <span style="color:#999;margin-top:2px;">•</span>
                    <div style="flex:1;">
                      <div style="display:flex;justify-content:space-between;align-items:baseline;">
                        <span class="papertitle">Harbin Institute of Technology (Shenzhen)</span>
                        <span style="white-space:nowrap;color:#888;font-size:0.9em;margin-left:20px;">2023.09 - Present</span>
                      </div>
                      <div style="line-height:1.5;margin-top:2px;">
                        Ph.D. in Electronic Information, School of Computer Science and Technology
                        <br>
                        Advised by Liqiang Nie and Xiang Deng
                      </div>
                      </div>
                    </div>
                  </div>
                </td>
              </tr>

              <tr>
                <td style="padding:5px 16px;width:100%;vertical-align:top;">
                  <div style="display:flex;gap:12px;">
                    <span style="color:#999;margin-top:2px;">•</span>
                    <div style="flex:1;">
                      <div style="display:flex;justify-content:space-between;align-items:baseline;">
                        <span class="papertitle">Great Bay University</span>
                        <span style="white-space:nowrap;color:#888;font-size:0.9em;margin-left:20px;">2023.09 - Present</span>
                      </div>
                      <div style="line-height:1.5;margin-top:2px;">
                        Ph.D. in Electronic Information, School of Engineering
                        <br>
                        Advised by Michael Yu Wang
                      </div>
                      </div>
                    </div>
                  </div>
                </td>
              </tr>

              <tr>
                <td style="padding:5px 16px;width:100%;vertical-align:top;">
                  <div style="display:flex;gap:12px;">
                    <span style="color:#999;margin-top:2px;">•</span>
                    <div style="flex:1;">
                      <div style="display:flex;justify-content:space-between;align-items:baseline;">
                        <span class="papertitle">National University of Singapore</span>
                        <span style="white-space:nowrap;color:#888;font-size:0.9em;margin-left:20px;">2025.10 - Present</span>
                      </div>
                      <div style="line-height:1.5;margin-top:2px;">
                        Visiting student, College of Design and Engineering
                        <br>
                        Advised by Mike Shou
                      </div>
                      </div>
                    </div>
                  </div>
                </td>
              </tr>

              <tr>
                <td style="padding:5px 16px;width:100%;vertical-align:top;">
                  <div style="display:flex;gap:12px;">
                    <span style="color:#999;margin-top:2px;">•</span>
                    <div style="flex:1;">
                      <div style="display:flex;justify-content:space-between;align-items:baseline;">
                        <span class="papertitle">Soochow University</span>
                        <span style="white-space:nowrap;color:#888;font-size:0.9em;margin-left:20px;">2020.09 - 2023.06</span>
                      </div>
                      <div style="line-height:1.5;margin-top:2px;">
                        M.S. in Computer Science and Technology, School of Computer Science and Technology
                      <br>
                      Advised by Guohong Fu
                      </div>
                    </div>
                  </div>
                </td>
              </tr>

              <tr>
                <td style="padding:5px 16px;width:100%;vertical-align:top;">
                  <div style="display:flex;gap:12px;">
                    <span style="color:#999;margin-top:2px;">•</span>
                    <div style="flex:1;">
                      <div style="display:flex;justify-content:space-between;align-items:baseline;">
                        <span class="papertitle">Soochow University</span>
                        <span style="white-space:nowrap;color:#888;font-size:0.9em;margin-left:20px;">2014.09 - 2018.06</span>
                      </div>
                      <div style="line-height:1.5;margin-top:2px;">
                        B.S. in Software Engineering, School of Computer Science and Technology
                      </div>
                    </div>
                  </div>
                </td>
              </tr>


          <!-- Footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="font-size:small;display:flex;justify-content:space-between;align-items:center;">
                    <span>Last updated: January 2026</span>
                    <span>Template by <a href="https://jonbarron.info/">Jon Barron</a>.</span>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>