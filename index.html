<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Qi Lv</title>

  <meta name="author" content="Qi Lv">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Qi Lv
                  </p>
                  <p>
                    I am a third-year Ph.D. student at Harbin Institute of Technology (Shenzhen) and Great Bay
                    University, advised by <a
                      href="https://scholar.google.com/citations?hl=zh-CN&user=Oo7c22wAAAAJ">Michael Yu Wang</a>
                    (IEEE/ASME/HKIE Fellow) and <a href="https://liqiangnie.github.io/index.html">Liqiang Nie</a> (IARP
                    Fellow), and co-supervised by <a href="https://xiang-deng-dl.github.io/">Xiang Deng</a>.
                    Before, I received M.S and B.E from Soochow University.

                    <br><br>
                    My research focuses on embodied AI and natural language processing, particularly on integrating
                    multimodal large language models with robotic systems. I am interested in enabling robots to better
                    perceive, reason, and act in the physical world through language-vision-action alignment.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:aopolin.ii@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/qilv_cv.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=4obt24UAAAAJ&hl">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/Aopolin">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://github.com/Aopolin-Lv/">Github</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/qi-lv-075614311/">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:27%;max-width:27%">
                  <a href="images/personal_pic.png"><img
                      style="width:100%;max-width:100%;aspect-ratio: 1/1;object-fit: cover; border-radius:50%;" alt="profile photo"
                      src="images/personal_pic.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Publications <span style="font-size: 14px; font-weight: normal;">(<eq>*</eq> denotes equal contribution)</span></h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="f1_stop()" onmouseover="f1_start()">
                <td style="padding:16px;width:40%;vertical-align:top">
                  <div class="one">
                    <div class="two" id='f1_image'>
                      <video width=100% height=100% muted autoplay loop>
                        <source src="images/f1-vla.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='images/f1-vla.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function f1_start() {
                      document.getElementById('f1_image').style.opacity = "1";
                    }

                    function f1_stop() {
                      document.getElementById('f1_image').style.opacity = "0";
                    }
                    f1_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:top">
                  <a href="https://aopolin-lv.github.io/F1-VLA/">
                    <span class="papertitle">F1: A Vision-Language-Action Model Bridging Understanding and Generation to
                      Actions</span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong><eq>*</eq>,
                  Weijie Kong<eq>*</eq>, Hao Li<eq>*</eq>, Jia Zeng, Zherui Qiu, Delin Qu, Haoming Song, Qizhi Chen, Xiang Deng, Jiangmiao Pang
                  <br>
                  arxiv, 2025
                  <br>
                  <a href="https://aopolin-lv.github.io/F1-VLA/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2509.06951">arXiv</a>
                  /
                  <a href="https://github.com/InternRobotics/F1-VLA">code</a>
                  &nbsp;
                  <a href="https://huggingface.co/InternRobotics/F1-VLA">
                    <img 
                        src="https://img.shields.io/badge/F1--VLA-Model-FF7F00?logo=huggingface&logoColor=brightyellow" 
                        alt="EO-1 Model"
                    />
                  </a>
                  <p></p>
                  <p>
                    A novel paradigm integrating visual foresight generation into the decision-making pipeline, enabling
                    robots to plan and execute complex tasks in dynamic environments.
                  </p>
                </td>
              </tr>

              <tr onmouseout="stard_stop()" onmouseover="stard_start()">
                <td style="padding:16px;width:40%;vertical-align:top">
                  <div class="one">
                    <div class="two" id='nexf_image'>
                      <img src='images/stard.png' width=100%>
                    </div>
                    <img src='images/stard.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function stard_start() {
                      document.getElementById('nexf_image').style.opacity = "1";
                    }

                    function stard_stop() {
                      document.getElementById('nexf_image').style.opacity = "0";
                    }
                    stard_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:top">
                  <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Lv_Spatial-Temporal_Graph_Diffusion_Policy_with_Kinematic_Modeling_for_Bimanual_Robotic_CVPR_2025_paper.html">
                    <span class="papertitle">Spatial-Temporal Graph Diffusion Policy with Kinematic Modeling for Bimanual Robotic Manipulation</span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong>, Hao Li, Xiang Deng, Rui Shao, Yinchuan Li, Jianye Hao, Longxiang Gao, Michael Yu Wang, Liqiang Nie
                  <br>
                  <em>CVPR</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2503.10743">arXiv</a>
                  <p></p>
                  <p>
                    KStar Diffuser leverages dynamic spatial-temporal robot graphs and differentiable kinematics to produce physically feasible, structure-aware bimanual manipulation policies.
                  </p>
                </td>
              </tr>

              <tr onmouseout="dm_stop()" onmouseover="dm_start()">
                <td style="padding:16px;width:40%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nexf_image'>
                      <img src='images/dm.png' width=100%>
                    </div>
                    <img src='images/dm.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function dm_start() {
                      document.getElementById('nexf_image').style.opacity = "1";
                    }

                    function dm_stop() {
                      document.getElementById('nexf_image').style.opacity = "0";
                    }
                    stard_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:bottom">
                  <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/288b63aa98084366c4536ba0574a0f22-Abstract-Conference.html">
                    <span class="papertitle">Decision Mamba: A Multi-Grained State Space Model with Self-Evolution Regularization for Offline RL</span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong>, Xiang Deng, Gongwei Chen, Michael Yu Wang, Liqiang Nie
                  <br>
                  <em>NeurIPS</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2503.10743">arXiv</a>
                  /
                  <a href="https://github.com/aopolin-lv/DecisionMamba">code</a>
                  <p></p>
                  <p>
                    We introduces a novel multi-grained Mamba architecture that jointly models historical hidden states and intra-step RTG–state–action relations, enabling more robust offline RL under out-of-distribution settings.
                  </p>
                </td>
              </tr>

              <tr onmouseout="robomp2_stop()" onmouseover="robomp2_start()">
                <td style="padding:16px;width:40%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nexf_image'>
                      <img src='images/robomp2.png' width=100%>
                    </div>
                    <img src='images/robomp2.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function robomp2_start() {
                      document.getElementById('nexf_image').style.opacity = "1";
                    }

                    function robomp2_stop() {
                      document.getElementById('nexf_image').style.opacity = "0";
                    }
                    stard_stop()
                  </script>
                </td>
                <td style="padding:8px;width:60%;vertical-align:bottom">
                  <a href="https://proceedings.mlr.press/v235/lv24a.html">
                    <span class="papertitle">RoboMP<sup>2</sup>: A Robotic Multimodal Perception-Planning Framework with Multimodal Large Language Models</span>
                  </a>
                  <br>
                  <strong>Qi Lv</strong>, Hao Li, Xiang Deng, Rui Shao, Michael Yu Wang, Liqiang Nie
                  <br>
                  <em>ICML</em>, 2024
                  <br>
                  <a href="https://aopolin-lv.github.io/RoboMP2.github.io/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2404.04929">arXiv</a>
                  /
                  <a href="https://github.com/aopolin-lv/RoboMP2">code</a>
                  <p></p>
                  <p>
                    We propose RoboMP<sup>2</sup>, a multimodal perception–planning framework that grounds MLLM reasoning in embodied robotic manipulation. It improves generalization by combining goal-conditioned perception with retrieval-augmented planning.
                  </p>
                </td>
              </tr>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:right;font-size:small;">
                        Template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>